{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "e9X0aZJVZ7BX"
      ],
      "authorship_tag": "ABX9TyNSu4u7rwC2NJb02oKAK+k7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/francianerod/Doutorado-ESAN-UFMS/blob/main/C%C3%93DIGO_TESE_PARTE_FINAL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **APÊNDICE A - CÓDIGO DE ANÁLISE DA ESTIAGEM DA CULTURA DA SOJA**"
      ],
      "metadata": {
        "id": "FwSumjTqC1qs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Abertura de biblioteca e dados**"
      ],
      "metadata": {
        "id": "nmVhlxRQ2g_b"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IFa2nby-wvna"
      },
      "outputs": [],
      "source": [
        "# Importação da biblioteca\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import warnings"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Ignorar avisos\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "metadata": {
        "id": "gyZw3ScAmX0w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Abertura dos dados\n",
        "df = pd.read_csv('/content/cpao_oficial_dados_1979_2023.csv', sep=';')"
      ],
      "metadata": {
        "id": "SGoAm42oxDm0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Mudança do tipo de dados da data\n",
        "df['data'] = pd.to_datetime(df['data'], format='%d/%m/%Y')"
      ],
      "metadata": {
        "id": "lzmJGVSXNWbb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Eliminando linhas vazias referentes a 2024.\n",
        "df = df.dropna()"
      ],
      "metadata": {
        "id": "CzHdvMhJX1AL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Médias climatológicas de Dourados**"
      ],
      "metadata": {
        "id": "9AFzgt_G1kPB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Período 1: 01/01/1980 a 31/12/2009\n",
        "periodo_1 = df[(df['data'] >= '1980-01-01') & (df['data'] <= '2009-12-31')]\n",
        "\n",
        "# Período 2: 01/01/1994 a 31/10/2023\n",
        "periodo_2 = df[(df['data'] >= '1994-01-01') & (df['data'] <= '2023-10-31')]"
      ],
      "metadata": {
        "id": "ROga0haa1jWD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Médias mensais para o período 1\n",
        "medias_mensais_periodo_1 = periodo_1.groupby(periodo_1['data'].dt.month)[['Tmedia', 'Tmax', 'Tmin']].mean()\n",
        "\n",
        "# Médias mensais para o período 2\n",
        "medias_mensais_periodo_2 = periodo_2.groupby(periodo_2['data'].dt.month)[['Tmedia', 'Tmax', 'Tmin']].mean()"
      ],
      "metadata": {
        "id": "lvnA5N-U3gmi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Organização dos dados\n",
        "meses = ['Janeiro', 'Fevereiro', 'Março', 'Abril', 'Maio', 'Junho', 'Julho', 'Agosto', 'Setembro', 'Outubro', 'Novembro', 'Dezembro']\n",
        "medias_mensais_periodo_1.index = meses\n",
        "medias_mensais_periodo_2.index = meses"
      ],
      "metadata": {
        "id": "ZTbuNiWu12H1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Configurando gráficos\n",
        "# Configurando o tamanho da figura\n",
        "plt.figure(figsize=(15, 7))\n",
        "\n",
        "# Plotando os dados do período 1\n",
        "plt.plot(medias_mensais_periodo_1.index, medias_mensais_periodo_1['Tmedia'], label='Período 1 (1980-2009)', marker='o')\n",
        "plt.plot(medias_mensais_periodo_1.index, medias_mensais_periodo_1['Tmax'], label='Período 1 (1980-2009) - Tmax', marker='o', linestyle='--')\n",
        "plt.plot(medias_mensais_periodo_1.index, medias_mensais_periodo_1['Tmin'], label='Período 1 (1980-2009) - Tmin', marker='o', linestyle='--')\n",
        "\n",
        "# Plotando os dados do período 2\n",
        "plt.plot(medias_mensais_periodo_2.index, medias_mensais_periodo_2['Tmedia'], label='Período 2 (1994-2023)', marker='s')\n",
        "plt.plot(medias_mensais_periodo_2.index, medias_mensais_periodo_2['Tmax'], label='Período 2 (1994-2023) - Tmax', marker='s', linestyle='--')\n",
        "plt.plot(medias_mensais_periodo_2.index, medias_mensais_periodo_2['Tmin'], label='Período 2 (1994-2023) - Tmin', marker='s', linestyle='--')\n",
        "\n",
        "# Adicionando título, rótulos dos eixos e legenda\n",
        "plt.title('Comparação das Médias Mensais de Temperatura em Dourados-MS')\n",
        "plt.xlabel('Mês')\n",
        "plt.ylabel('Temperatura (°C)')\n",
        "plt.legend() #loc='upper center', bbox_to_anchor=(0.5, -0.15), fancybox=True, shadow=True, ncol=5\n",
        "plt.grid(True)\n",
        "\n",
        "# Rotacionando os rótulos do eixo x para melhor visualização\n",
        "plt.xticks(rotation=45)\n",
        "\n",
        "# Exibindo o gráfico\n",
        "plt.tight_layout() # ajusta o layout para evitar sobreposição de elementos\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "c__9Trq-4btV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Agrupa os dados por ano e mês e soma a chuva\n",
        "chuva_acumulada_periodo_1 = periodo_1.groupby([periodo_1['data'].dt.year, periodo_1['data'].dt.month])['chuva'].sum()\n",
        "chuva_acumulada_periodo_2 = periodo_2.groupby([periodo_2['data'].dt.year, periodo_2['data'].dt.month])['chuva'].sum()\n",
        "\n",
        "\n",
        "# Calcula a média mensal do acumulado de chuva para cada período\n",
        "media_chuva_mensal_periodo_1 = chuva_acumulada_periodo_1.groupby(level=1).mean()\n",
        "media_chuva_mensal_periodo_2 = chuva_acumulada_periodo_2.groupby(level=1).mean()\n",
        "\n",
        "# Define os nomes dos meses para o índice\n",
        "meses = ['Janeiro', 'Fevereiro', 'Março', 'Abril', 'Maio', 'Junho', 'Julho', 'Agosto', 'Setembro', 'Outubro', 'Novembro', 'Dezembro']\n",
        "media_chuva_mensal_periodo_1.index = meses\n",
        "media_chuva_mensal_periodo_2.index = meses"
      ],
      "metadata": {
        "id": "tWeC5fvf7sqG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Configurando o tamanho da figura\n",
        "plt.figure(figsize=(15, 7))\n",
        "\n",
        "# Dados para o gráfico\n",
        "meses = media_chuva_mensal_periodo_1.index  # Usando os meses do período 1 como eixo x\n",
        "chuva_periodo_1 = media_chuva_mensal_periodo_1.values\n",
        "chuva_periodo_2 = media_chuva_mensal_periodo_2.values\n",
        "\n",
        "# Criando o gráfico\n",
        "plt.figure(figsize=(12, 6))  # Define o tamanho da figura\n",
        "plt.plot(meses, chuva_periodo_1, label='Período 1 (1980-2009)', marker='o')\n",
        "plt.plot(meses, chuva_periodo_2, label='Período 2 (1994-2023)', marker='s')\n",
        "\n",
        "# Personalizando o gráfico\n",
        "plt.title('Comparação da Média Mensal de Chuva Acumulada em Dourados-MS')\n",
        "plt.xlabel('Mês')\n",
        "plt.ylabel('Chuva Acumulada (mm)')\n",
        "plt.xticks(rotation=45, ha='right')  # Rotaciona os rótulos do eixo x para melhor visualização\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "\n",
        "# Exibindo o gráfico\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "1ExRSnwf8Sy8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Filtrar os dados para o período entre setembro e março\n",
        "periodo_setembro_marco = df[(df['data'].dt.month >= 9) | (df['data'].dt.month <= 3)]\n",
        "\n",
        "# Encontrar a temperatura máxima e sua data\n",
        "data_temperatura_maxima = periodo_setembro_marco.loc[periodo_setembro_marco['Tmax'].idxmax(), 'data']\n",
        "temperatura_maxima = periodo_setembro_marco['Tmax'].max()\n",
        "\n",
        "# Encontrar a temperatura mínima e sua data\n",
        "data_temperatura_minima = periodo_setembro_marco.loc[periodo_setembro_marco['Tmin'].idxmin(), 'data']\n",
        "temperatura_minima = periodo_setembro_marco['Tmin'].min()\n",
        "\n",
        "\n",
        "# Encontrar o acumulado de chuva máximo em um dia e sua data\n",
        "data_chuva_maxima = periodo_setembro_marco.loc[periodo_setembro_marco['chuva'].idxmax(), 'data']\n",
        "chuva_maxima_dia = periodo_setembro_marco['chuva'].max()\n",
        "\n",
        "# Imprimir os resultados\n",
        "print(f\"Temperatura máxima entre setembro e março: {temperatura_maxima:.2f} °C em {data_temperatura_maxima.date()}\")\n",
        "print(f\"Temperatura mínima entre setembro e março: {temperatura_minima:.2f} °C em {data_temperatura_minima.date()}\")\n",
        "print(f\"Acumulado de chuva máximo em um dia entre setembro e março: {chuva_maxima_dia:.2f} mm em {data_chuva_maxima.date()}\")"
      ],
      "metadata": {
        "id": "TP44aSVZLNxA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Construindo indicador de estiagem usando apenas a Precipitação**"
      ],
      "metadata": {
        "id": "S4gZD14wm7K6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Apenas a coluna de chuva\n",
        "df_chuva = df[['data', 'chuva']]"
      ],
      "metadata": {
        "id": "9tRkAzGZnIqk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Janelas Móveis (Rolling Windows): Utilizando a soma acumulada de 5 dias para capturar o comportamento da precipitação no curto prazo.\n",
        "# Calculando o acumulado de precipitação dos últimos 5 e 10 dias\n",
        "df_chuva['acumulado5dias'] = df_chuva['chuva'].rolling(window=5, min_periods=1).sum()\n",
        "df_chuva['acumulado10dias'] = df_chuva['chuva'].rolling(window=10, min_periods=1).sum()"
      ],
      "metadata": {
        "id": "yFAdfAgFnEFS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Janelas Móveis (Rolling Windows): Utilizando a soma acumulada de 5 dias para capturar o comportamento da precipitação no curto prazo.\n",
        "# Calculando o acumulado de precipitação dos últimos 5 e 10 dias\n",
        "df_chuva['acumulado5dias'] = df_chuva['chuva'].rolling(window=5, min_periods=1).sum()\n",
        "df_chuva['acumulado10dias'] = df_chuva['chuva'].rolling(window=10, min_periods=1).sum()"
      ],
      "metadata": {
        "id": "j2KJU3JQEhsr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Agora df_chuva\n",
        "df_chuva.describe()"
      ],
      "metadata": {
        "id": "g9m-AzN0Et2x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Filtrar os dados para o período entre setembro e março -periodo em que se planta soja\n",
        "df_chuva_setembro_marco = df_chuva[(df_chuva['data'].dt.month >= 9) | (df_chuva['data'].dt.month <= 3)]"
      ],
      "metadata": {
        "id": "GYkXIqyPEt0Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Estatística descritiva da safra\n",
        "df_chuva_setembro_marco.describe()"
      ],
      "metadata": {
        "id": "DxzlEdJ_9aRT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Boxplot do df_chuva_setembro_marco das colunas chuva, acumulado5dias, acumulado10dias no plotly\n",
        "\n",
        "import plotly.graph_objects as go\n",
        "fig = go.Figure()\n",
        "fig.add_trace(go.Box(y=df_chuva_setembro_marco['chuva'], name='Chuva'))\n",
        "fig.add_trace(go.Box(y=df_chuva_setembro_marco['acumulado5dias'], name='Acumulado 5 dias'))\n",
        "fig.add_trace(go.Box(y=df_chuva_setembro_marco['acumulado10dias'], name='Acumulado 10 dias'))\n",
        "\n",
        "fig.update_layout(title_text=\"Boxplot da Chuva e Acumulados (Setembro-Março)\", yaxis_title=\"mm\")\n",
        "fig.show()\n"
      ],
      "metadata": {
        "id": "xEalEYfH9aJb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Removendo os Outliers e deixar entre os valores máximos e minimos.\n",
        "import plotly.graph_objects as go\n",
        "\n",
        "# Função para remover outliers usando o IQR\n",
        "def remove_outliers(df, column):\n",
        "    Q1 = df[column].quantile(0.25)\n",
        "    Q3 = df[column].quantile(0.75)\n",
        "    IQR = Q3 - Q1\n",
        "    lower_bound = Q1 - 1.5 * IQR\n",
        "    upper_bound = Q3 + 1.5 * IQR\n",
        "    return df[(df[column] >= lower_bound) & (df[column] <= upper_bound)]\n",
        "\n",
        "# Aplicar a remoção de outliers para cada variável\n",
        "df_chuva_filtrado = remove_outliers(df_chuva_setembro_marco, 'chuva')\n",
        "df_acumulado5dias_filtrado = remove_outliers(df_chuva_setembro_marco, 'acumulado5dias')\n",
        "df_acumulado10dias_filtrado = remove_outliers(df_chuva_setembro_marco, 'acumulado10dias')\n",
        "\n",
        "# Criar um novo DataFrame apenas com os dados filtrados\n",
        "df_chuva_setembro_marco_no_outliers = pd.DataFrame({\n",
        "    'chuva': df_chuva_filtrado['chuva'],\n",
        "    'acumulado5dias': df_acumulado5dias_filtrado['acumulado5dias'],\n",
        "    'acumulado10dias': df_acumulado10dias_filtrado['acumulado10dias']\n",
        "})\n",
        "\n",
        "# Criar o gráfico sem outliers interferindo nos cálculos estatísticos\n",
        "fig = go.Figure()\n",
        "fig.add_trace(go.Box(y=df_chuva_setembro_marco_no_outliers['chuva'], name='Chuva', boxpoints=False))\n",
        "fig.add_trace(go.Box(y=df_chuva_setembro_marco_no_outliers['acumulado5dias'], name='Acumulado 5 dias', boxpoints=False))\n",
        "fig.add_trace(go.Box(y=df_chuva_setembro_marco_no_outliers['acumulado10dias'], name='Acumulado 10 dias', boxpoints=False))\n",
        "\n",
        "fig.update_layout(title_text=\"Boxplot da Chuva e Acumulados (Setembro-Março) - Sem Outliers\", yaxis_title=\"mm\")\n",
        "fig.show()\n"
      ],
      "metadata": {
        "id": "ioa6zYjljpYS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Verifique se a filtragem funcionou\n",
        "df_chuva_setembro_marco.describe() # Antes da filtragem"
      ],
      "metadata": {
        "id": "U2_3zaWwkmx4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# RESULTADO: INDICADOR A SER USADO PARA ESTIAGEM: A MÉDIA SEM INTERFERÊNCIA DE OUTLIERS\n",
        "# Informações da média foram usadas na planilha em excel para decidir qual melhor indicador.\n",
        "df_chuva_setembro_marco_no_outliers.describe()  # Depois da filtragem"
      ],
      "metadata": {
        "id": "be_3QptOkoXa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Pré-processamento e teste de ML**"
      ],
      "metadata": {
        "id": "5zsEU7hcn-Si"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Janelas Móveis (Rolling Windows): Utilizando a soma acumulada de 5 dias para capturar o comportamento da precipitação no curto prazo.\n",
        "# Calculando o acumulado de precipitação dos últimos 5 e 10 dias\n",
        "df['acumulado5dias'] = df['chuva'].rolling(window=5, min_periods=1).sum()\n",
        "df['acumulado10dias'] = df['chuva'].rolling(window=10, min_periods=1).sum()"
      ],
      "metadata": {
        "id": "kuXRXqsboz3B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Criando features referentes a data\n",
        "df['ano'] = df['data'].dt.year\n",
        "df['mes'] = df['data'].dt.month\n",
        "df['dia_do_ano'] = df['data'].dt.dayofyear"
      ],
      "metadata": {
        "id": "-d2QCZosq7D9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Criando novas variáveis derivadas\n",
        "df[\"variacao_ac_5_10\"] = df[\"acumulado5dias\"] / (df[\"acumulado10dias\"] + 1)"
      ],
      "metadata": {
        "id": "_15OTlSgONgz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Aplicando a regra para determinar estiagem sobre a variável de 5 dias acumulado determinado pela estatística\n",
        "df['estiagem'] = df['acumulado5dias'].apply(lambda x: 1 if x < 20.6 else 0)"
      ],
      "metadata": {
        "id": "al9qlLujpfTD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Avaliação de correlação\n",
        "correlation = df.corr(method='pearson')\n",
        "mascara = np.triu(np.ones_like(correlation, dtype=bool))\n",
        "plt.figure(figsize = ((8, 5)))\n",
        "plot = sns.heatmap(correlation,\n",
        "                   mask=mascara,\n",
        "                   annot = True,\n",
        "                   fmt=\".2f\", vmax=1, center=0, vmin=-1,\n",
        "                   cbar=True, cmap='coolwarm',\n",
        "                   linewidths=.5,\n",
        "                   cbar_kws={\"shrink\": .5, 'label': 'Correlação', 'orientation': 'vertical'})\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "qNZiyvDEEECf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Verificação de desbalanceamento\n",
        "estiagem_counts = df['estiagem'].value_counts()\n",
        "estiagem_counts"
      ],
      "metadata": {
        "id": "bNNTnMHaozxj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Instalação de pacote\n",
        "!pip install lazypredict\n",
        "!pip install imblearn"
      ],
      "metadata": {
        "id": "pYz7VsszqJrF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Importando bibliotecas\n",
        "import pandas as pd\n",
        "import lazypredict\n",
        "from lazypredict.Supervised import LazyClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "# Separando as variáveis explicativas (X) e a variável target (y)\n",
        "X = df.drop(columns=[\"data\", \"Tmax\", \"Tmin\",\"acumulado5dias\", \"acumulado10dias\", \"estiagem\"])\n",
        "y = df[\"estiagem\"]\n",
        "\n",
        "# Dividindo os dados antes do balanceamento\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
        "\n",
        "# Aplicar SMOTE apenas no conjunto de treino\n",
        "over_sampler = SMOTE(random_state=42)\n",
        "X_train_resampled, y_train_resampled = over_sampler.fit_resample(X_train, y_train)\n",
        "\n",
        "# Inicializando o classificador LazyClassifier\n",
        "clf = LazyClassifier(verbose=0, ignore_warnings=True, custom_metric=None)\n",
        "\n",
        "# Treinando o modelo com os dados de treino balanceados\n",
        "models, predictions = clf.fit(X_train_resampled, X_test, y_train_resampled, y_test)\n",
        "\n",
        "# Imprimindo os resultados\n",
        "models"
      ],
      "metadata": {
        "id": "uApqQ09hqWBF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Separando dados de Treino/Teste e Validação**"
      ],
      "metadata": {
        "id": "e9X0aZJVZ7BX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Conjunto de Dados Oficial\n",
        "df"
      ],
      "metadata": {
        "id": "_sEaVIGUZ6cz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Definindo as datas divididas - Para os testes\n",
        "date_split_train_test = pd.to_datetime('2021-08-31')\n",
        "date_split_valid = pd.to_datetime('2021-09-01')\n",
        "\n",
        "# Criando o df1_train_test\n",
        "df1_train_test = df[df['data'] <= date_split_train_test]\n",
        "\n",
        "# Criando o df2_valid\n",
        "df2_valid = df[(df['data'] >= date_split_valid) & (df['data'] <= pd.to_datetime('2023-12-31'))]\n",
        "\n",
        "print(\"df1_train_test shape:\", df1_train_test.shape)\n",
        "print(\"df2_valid shape:\", df2_valid.shape)"
      ],
      "metadata": {
        "id": "8WKd38RVxxNW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Criando df2_ruim (2021-09-01 a 2022-03-31)\n",
        "df2_ruim = df2_valid[(df2_valid['data'] >= '2021-09-01') & (df2_valid['data'] <= '2022-03-31')]\n",
        "\n",
        "# Criando df2_boa (2022-09-01 a 2023-03-31)\n",
        "df2_boa = df2_valid[(df2_valid['data'] >= '2022-09-01') & (df2_valid['data'] <= '2023-03-31')]\n",
        "\n",
        "print(\"df2_ruim shape:\", df2_ruim.shape)\n",
        "print(\"df2_boa shape:\", df2_boa.shape)"
      ],
      "metadata": {
        "id": "hlM56h447aNf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Classificação: Machine Learning**"
      ],
      "metadata": {
        "id": "tOzsYsXm8aPd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Bases separadas:**\n",
        "\n",
        "* df - original para construir o conjunto de dados\n",
        "* df1_train_test - treinamento e testes do ML (1979-06-01 a 2021-08-31) - 15429 informações\n",
        "* df2_valid - validações do ML (01-09-2021 a 31-12-2023)\n",
        "    * df2_ruim (2021-09-01 a 2022-03-31)\n",
        "    * df2_boa (2022-09-01 a 2023-03-31)\n"
      ],
      "metadata": {
        "id": "bIou4SiC78Ov"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Bibliotecas importantes\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report"
      ],
      "metadata": {
        "id": "PkmLxWZ9-hPq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Base de Dados de Treinamento e Teste\n",
        "df1_train_test.info()"
      ],
      "metadata": {
        "id": "z6WQid42ODS5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Separando as variáveis explicativas (X) e a variável target (y)\n",
        "# Tmedia, chuva, ano, mes, dia_do_ano, variacao_ac_5_10\n",
        "# estiagem (0,1)\n",
        "\n",
        "X = df1_train_test.drop(columns=[\"data\", \"Tmax\", \"Tmin\",\"acumulado5dias\", \"acumulado10dias\", \"estiagem\"])\n",
        "y = df1_train_test[\"estiagem\"]"
      ],
      "metadata": {
        "id": "PiR-QHkg9STU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dividindo os dados antes do balanceamento\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
        "\n",
        "# Aplicar SMOTE apenas no conjunto de treino\n",
        "over_sampler = SMOTE(random_state=42)\n",
        "X_train_resampled, y_train_resampled = over_sampler.fit_resample(X_train, y_train)"
      ],
      "metadata": {
        "id": "xGX6rf1w-ErZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Função Classificação\n",
        "def print_score(clf, X_train, y_train, X_test, y_test, train=True):\n",
        "    if train:\n",
        "        pred = clf.predict(X_train)\n",
        "        clf_report = pd.DataFrame(classification_report(y_train, pred, output_dict=True))\n",
        "        print(\"Resultado do treinamento:\\n================================================\")\n",
        "        print(f\"Accuracy Score: {accuracy_score(y_train, pred) * 100:.2f}%\")\n",
        "        print(\"_______________________________________________\")\n",
        "        print(f\"Relatório de classificação:\\n{clf_report}\")\n",
        "        print(\"_______________________________________________\")\n",
        "        print(f\"Confusion Matrix: \\n {confusion_matrix(y_train, pred)}\\n\")\n",
        "\n",
        "    elif train==False:\n",
        "        pred = clf.predict(X_test)\n",
        "        clf_report = pd.DataFrame(classification_report(y_test, pred, output_dict=True))\n",
        "        print(\"Resultado do teste:\\n================================================\")\n",
        "        print(f\"Accuracy Score: {accuracy_score(y_test, pred) * 100:.2f}%\")\n",
        "        print(\"_______________________________________________\")\n",
        "        print(f\"Relatório de classificação:\\n{clf_report}\")\n",
        "        print(\"_______________________________________________\")\n",
        "        print(f\"Confusion Matrix: \\n {confusion_matrix(y_test, pred)}\\n\")"
      ],
      "metadata": {
        "id": "WkMri-oQ7aK3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Importando a biblioteca necessária\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Inicializando o classificador RandomForestClassifier com hiperparâmetros ajustados\n",
        "rf_clf = RandomForestClassifier(random_state=42,               # Para reprodutibilidade\n",
        "                                n_estimators=200,              # Número de árvores na floresta\n",
        "                                max_depth=15,                  # Profundidade máxima das árvores (None permite crescimento ilimitado)\n",
        "                                min_samples_split=5,           # Número mínimo de amostras para dividir um nó\n",
        "                                min_samples_leaf=1,            # Número mínimo de amostras em um nó folha\n",
        "                                )\n",
        "# Treinando o modelo com os dados de treino balanceados\n",
        "rf_clf.fit(X_train_resampled, y_train_resampled)\n",
        "\n",
        "# Fazendo previsões\n",
        "y_pred_rf = rf_clf.predict(X_test)\n",
        "\n",
        "#Relatório de Resultados\n",
        "print_score(rf_clf, X_train_resampled, y_train_resampled, X_test, y_test, train=True)\n",
        "print_score(rf_clf, X_train_resampled, y_train_resampled, X_test, y_test, train=False)"
      ],
      "metadata": {
        "id": "MybpvQ01LvPZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Importando a biblioteca necessária\n",
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "\n",
        "# Inicializando o ExtraTreesClassifier\n",
        "et_clf = ExtraTreesClassifier(n_estimators=200,\n",
        "                              max_depth=15,\n",
        "                              min_samples_split=5,\n",
        "                              min_samples_leaf=2,\n",
        "                              random_state=42)\n",
        "\n",
        "# Treinando o modelo com os dados balanceados\n",
        "et_clf.fit(X_train_resampled, y_train_resampled)\n",
        "\n",
        "# Fazendo previsões\n",
        "y_pred_et = et_clf.predict(X_test)\n",
        "\n",
        "#Relatório de Resultados\n",
        "print_score(et_clf, X_train_resampled, y_train_resampled, X_test, y_test, train=True)\n",
        "print_score(et_clf, X_train_resampled, y_train_resampled, X_test, y_test, train=False)"
      ],
      "metadata": {
        "id": "IKWgHfA4JTd1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Importando a biblioteca necessária\n",
        "import xgboost as xgb\n",
        "\n",
        "# Inicializando o classificador XGBClassifier\n",
        "xgb_clf = xgb.XGBClassifier(random_state=42,\n",
        "                            use_label_encoder=False,\n",
        "                            eval_metric='logloss',\n",
        "                            )\n",
        "\n",
        "# Treinando o modelo com os dados de treino balanceados\n",
        "xgb_clf.fit(X_train_resampled, y_train_resampled)\n",
        "\n",
        "\n",
        "# Fazendo previsões\n",
        "y_pred_xgb = xgb_clf.predict(X_test)\n",
        "\n",
        "#Relatório de Resultados\n",
        "print_score(xgb_clf, X_train_resampled, y_train_resampled, X_test, y_test, train=True)\n",
        "print_score(xgb_clf, X_train_resampled, y_train_resampled, X_test, y_test, train=False)"
      ],
      "metadata": {
        "id": "BEdobguRJ40T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Validação**"
      ],
      "metadata": {
        "id": "AJYUwLBkfC_7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Teste Safra Ruim de 2021-2022**"
      ],
      "metadata": {
        "id": "hEPft62upq20"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Original para validação\n",
        "df2_ruim"
      ],
      "metadata": {
        "id": "rLdtDwT6mtgn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Separando as informações da base de treino e teste sem o rótulo\n",
        "X_unlabeled_ruim = df2_ruim.drop(columns=[\"data\", \"Tmax\", \"Tmin\",\"acumulado5dias\", \"acumulado10dias\", \"estiagem\"])"
      ],
      "metadata": {
        "id": "NPsU8xkmmr5v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# A tabela para validação tem de ser a mesma do treinamento e teste\n",
        "X_unlabeled_ruim"
      ],
      "metadata": {
        "id": "4vyImBENJTWK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Teste de Validação: RandomForestClassifier\n",
        "\n",
        "# Prevendo rótulos para o conjunto de dados não rotulado\n",
        "y_pred_unlabeled = rf_clf.predict(X_unlabeled_ruim)\n",
        "\n",
        "# Contando a quantidade de rótulos 0 e 1\n",
        "counts = np.bincount(y_pred_unlabeled)\n",
        "\n",
        "# Calculando a porcentagem\n",
        "total = len(y_pred_unlabeled)\n",
        "percent_1 = (counts[1] / total) * 100\n",
        "percent_0 = (counts[0] / total) * 100\n",
        "\n",
        "# Exibindo a quantidade e a porcentagem de 0s e 1s\n",
        "print(f\"Quantidade de 1 - com estiagem: {counts[1]} ({percent_1:0.0f}%)\")\n",
        "print(f\"Quantidade de 0 - sem estiagem: {counts[0]} ({percent_0:0.0f}%)\")\n"
      ],
      "metadata": {
        "id": "2GLa14Zxqaap"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Teste de Validação: ExtraTreesClassifier\n",
        "\n",
        "# Prevendo rótulos para o conjunto de dados não rotulado\n",
        "y_pred_unlabeled = et_clf.predict(X_unlabeled_ruim)\n",
        "\n",
        "# Contando a quantidade de rótulos 0 e 1\n",
        "counts = np.bincount(y_pred_unlabeled)\n",
        "\n",
        "# Calculando a porcentagem\n",
        "total = len(y_pred_unlabeled)\n",
        "percent_1 = (counts[1] / total) * 100\n",
        "percent_0 = (counts[0] / total) * 100\n",
        "\n",
        "# Exibindo a quantidade e a porcentagem de 0s e 1s\n",
        "print(f\"Quantidade de 1 - com estiagem: {counts[1]} ({percent_1:0.0f}%)\")\n",
        "print(f\"Quantidade de 0 - sem estiagem: {counts[0]} ({percent_0:0.0f}%)\")"
      ],
      "metadata": {
        "id": "TqvJzmIfrT9M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Teste de Validação: XGBClassifier\n",
        "\n",
        "# Prevendo rótulos para o conjunto de dados não rotulado\n",
        "y_pred_unlabeled = xgb_clf.predict(X_unlabeled_ruim)\n",
        "\n",
        "# Contando a quantidade de rótulos 0 e 1\n",
        "counts = np.bincount(y_pred_unlabeled)\n",
        "\n",
        "# Calculando a porcentagem\n",
        "total = len(y_pred_unlabeled)\n",
        "percent_1 = (counts[1] / total) * 100\n",
        "percent_0 = (counts[0] / total) * 100\n",
        "\n",
        "# Exibindo a quantidade e a porcentagem de 0s e 1s\n",
        "print(f\"Quantidade de 1 - com estiagem: {counts[1]} ({percent_1:0.0f}%)\")\n",
        "print(f\"Quantidade de 0 - sem estiagem: {counts[0]} ({percent_0:0.0f}%)\")"
      ],
      "metadata": {
        "id": "oPgGvAntrTv9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Teste Safra Boa de 2022-2023**"
      ],
      "metadata": {
        "id": "5OIubEcMttQH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Original para validação\n",
        "df2_boa"
      ],
      "metadata": {
        "id": "iXDLLi8qqJhn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Separando as informações da base de treino e teste sem o rótulo\n",
        "X_unlabeled_boa = df2_boa.drop(columns=[\"data\", \"Tmax\", \"Tmin\",\"acumulado5dias\", \"acumulado10dias\", \"estiagem\"])"
      ],
      "metadata": {
        "id": "V_U0x1sCt4ON"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Teste de Validação: RandomForestClassifier\n",
        "\n",
        "# Prevendo rótulos para o conjunto de dados não rotulado\n",
        "y_pred_unlabeled = rf_clf.predict(X_unlabeled_boa)\n",
        "\n",
        "# Contando a quantidade de rótulos 0 e 1\n",
        "counts = np.bincount(y_pred_unlabeled)\n",
        "\n",
        "# Calculando a porcentagem\n",
        "total = len(y_pred_unlabeled)\n",
        "percent_1 = (counts[1] / total) * 100\n",
        "percent_0 = (counts[0] / total) * 100\n",
        "\n",
        "# Exibindo a quantidade e a porcentagem de 0s e 1s\n",
        "print(f\"Quantidade de 1 - com estiagem: {counts[1]} ({percent_1:0.0f}%)\")\n",
        "print(f\"Quantidade de 0 - sem estiagem: {counts[0]} ({percent_0:0.0f}%)\")"
      ],
      "metadata": {
        "id": "8oPNLKiPuER4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Teste de Validação: ExtraTreesClassifier\n",
        "\n",
        "# Prevendo rótulos para o conjunto de dados não rotulado\n",
        "y_pred_unlabeled = et_clf.predict(X_unlabeled_boa)\n",
        "\n",
        "# Contando a quantidade de rótulos 0 e 1\n",
        "counts = np.bincount(y_pred_unlabeled)\n",
        "\n",
        "# Calculando a porcentagem\n",
        "total = len(y_pred_unlabeled)\n",
        "percent_1 = (counts[1] / total) * 100\n",
        "percent_0 = (counts[0] / total) * 100\n",
        "\n",
        "# Exibindo a quantidade e a porcentagem de 0s e 1s\n",
        "print(f\"Quantidade de 1 - com estiagem: {counts[1]} ({percent_1:0.0f}%)\")\n",
        "print(f\"Quantidade de 0 - sem estiagem: {counts[0]} ({percent_0:0.0f}%)\")"
      ],
      "metadata": {
        "id": "6DzmMZMYuER5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Teste de Validação: XGBClassifier\n",
        "\n",
        "# Prevendo rótulos para o conjunto de dados não rotulado\n",
        "y_pred_unlabeled = xgb_clf.predict(X_unlabeled_boa)\n",
        "\n",
        "# Contando a quantidade de rótulos 0 e 1\n",
        "counts = np.bincount(y_pred_unlabeled)\n",
        "\n",
        "# Calculando a porcentagem\n",
        "total = len(y_pred_unlabeled)\n",
        "percent_1 = (counts[1] / total) * 100\n",
        "percent_0 = (counts[0] / total) * 100\n",
        "\n",
        "# Exibindo a quantidade e a porcentagem de 0s e 1s\n",
        "print(f\"Quantidade de 1 - com estiagem: {counts[1]} ({percent_1:0.0f}%)\")\n",
        "print(f\"Quantidade de 0 - sem estiagem: {counts[0]} ({percent_0:0.0f}%)\")"
      ],
      "metadata": {
        "id": "_ROWe93xuER5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Arcabouço de Solow - Aplicação**"
      ],
      "metadata": {
        "id": "F8cRQKPzh15Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importação das bibliotecas\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "\n",
        "# Estilo do Seaborn\n",
        "sns.set(style=\"whitegrid\", palette=\"deep\")\n",
        "\n",
        "# Valores de capital (K)\n",
        "K = np.linspace(1, 100, 100)\n",
        "\n",
        "# Parâmetros da função de produção Cobb-Douglas\n",
        "A1 = 1.0   # Progresso técnico inicial\n",
        "A2 = 1.2   # Progresso técnico aumentado (20%)\n",
        "alpha = 0.3\n",
        "L = 1      # Trabalho constante\n",
        "\n",
        "# Funções de produção\n",
        "Y1 = A1 * (K ** alpha) * (L ** (1 - alpha))\n",
        "Y2 = A2 * (K ** alpha) * (L ** (1 - alpha))\n",
        "\n",
        "# Plot com cores específicas do Seaborn (verde e azul)\n",
        "plt.figure(figsize=(9, 6))\n",
        "plt.plot(K, Y1, label='A = 1,0 (nível tecnológico inicial)', color=sns.color_palette(\"deep\")[2])  # verde\n",
        "plt.plot(K, Y2, label='A = 1,2 (com progresso técnico)', color=sns.color_palette(\"deep\")[0])      # azul\n",
        "\n",
        "# Títulos e rótulos\n",
        "#plt.title('Impacto do Progresso Técnico sobre o Produto Total\\nFunção de Produção Cobb-Douglas', fontsize=13)\n",
        "plt.xlabel('Capital (K)', fontsize=11)\n",
        "plt.ylabel('Produto Total (Y)', fontsize=11)\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Vg1Gu9uKh9nA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}